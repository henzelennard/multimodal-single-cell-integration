{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56fbd065-3dc5-4e7c-93ca-49d128837dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import hdf5plugin\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c45db9cb-577b-4d79-a515-2e782bcd4f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.environ['DATA_DIR']\n",
    "f_name = 'train_multi_inputs'\n",
    "\n",
    "from_path = Path(data_path + f_name + '.h5')\n",
    "to_path = Path(data_path + f_name + '_T.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcff77ea-12cf-43c7-93fe-b7ddeeca8e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26e2af262d0442ba5f84eaab09a76a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# transform and copy main chunk\n",
    "with h5py.File(from_path, 'r') as from_file, h5py.File(to_path, 'w') as to_file:\n",
    "    # copy index and columnnames\n",
    "    in_and_col_names = [('axis0', 'accessibility'), ('axis1', 'cell')]\n",
    "    for ds_old, ds_new in in_and_col_names:\n",
    "        from_dset = from_file[f_name + '/' + ds_old]\n",
    "        to_dset = to_file.create_dataset(ds_new, from_dset.shape, dtype=from_dset.dtype, compression=\"gzip\")\n",
    "        to_dset[:] = from_dset[:]\n",
    "\n",
    "    # create dataset objects\n",
    "    from_dset = from_file[f_name + '/block0_values']\n",
    "    to_dset = to_file.create_dataset('values', from_dset.shape[::-1], dtype=from_dset.dtype, compression=\"gzip\")\n",
    "\n",
    "    # iterate over old dataset\n",
    "    batchsize = 40000\n",
    "    iterations = int(np.ceil(from_dset.shape[1] / batchsize))\n",
    "    \n",
    "    for i in tqdm(range(iterations)):\n",
    "        to_dset[i*batchsize:(i+1)*batchsize, :] = from_dset[:, i*batchsize: (i+1)*batchsize].T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:msci]",
   "language": "python",
   "name": "conda-env-msci-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
