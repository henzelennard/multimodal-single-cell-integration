{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df46475a-d644-4bd9-89af-97e72a41b5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "import hdf5plugin\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3340dfda-dfec-4f41-abab-937594f82caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../input/open-problems-multimodal/test_multi_inputs.h5'),\n",
       " PosixPath('../input/open-problems-multimodal/train_cite_targets.h5'),\n",
       " PosixPath('../input/open-problems-multimodal/train_multi_inputs.h5'),\n",
       " PosixPath('../input/open-problems-multimodal/train_cite_inputs.h5'),\n",
       " PosixPath('../input/open-problems-multimodal/train_multi_targets.h5'),\n",
       " PosixPath('../input/open-problems-multimodal/test_cite_inputs.h5')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# list of files we want to analyse\n",
    "f_list = list(Path('../input/open-problems-multimodal/').glob('./*[!T8].h5'))\n",
    "f_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09ed3cdb-9616-41b1-8c86-fab25e83b396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../working')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define output directory\n",
    "out_dir = Path('../working/')\n",
    "out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd4294a2-02e2-4d4f-abf4-e4b4cce0cf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "# field is an np.ndarray only containing zeros and ones\n",
    "def get_naive_n_tuples(field, max_depth):\n",
    "    naive_num_tuples = []\n",
    "    #append one-tuples (=number of elements) to naive tuple count\n",
    "    naive_num_tuples.append(field.sum(dim=1))\n",
    "    \n",
    "    # iterativeley calculate a new field. 1 in the field means, beginning \n",
    "    # of n tuple\n",
    "    prev_field = field.clone().detach()\n",
    "    for i in range(max_depth):\n",
    "        prev_field = prev_field[:,:-1] * field[:,i+1:]\n",
    "        naive_num_tuples.append(prev_field.sum(dim=1))\n",
    "        \n",
    "        #if not prev_field.any():\n",
    "        #    return naive_num_tuples\n",
    "            \n",
    "    return naive_num_tuples\n",
    "\n",
    "# naive n_tuples adds 2 2-tuple counts for every 3-tuple and so on\n",
    "# this function removes that\n",
    "def clean_naive_n_tuples(n_tuples):\n",
    "    reversed_n_tuples = list(reversed(n_tuples))\n",
    "    # add first element\n",
    "    reverse_clean_tuples = []\n",
    "    for i in range(len(reversed_n_tuples)):\n",
    "        reverse_clean_tuples.append(reversed_n_tuples[i].clone().detach())\n",
    "        \n",
    "        # correct number\n",
    "        for j in range(i):\n",
    "            reverse_clean_tuples[i] -= (i+1-j) * reverse_clean_tuples[j] \n",
    "        \n",
    "    return list(reversed(reverse_clean_tuples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bda0d17d-2933-4231-a64a-2ce3295f9b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the features we want to calculate for every cell\n",
    "target_features = {\n",
    "    'count_non_zero': torch.zeros(105942, dtype=torch.int32, device=device),\n",
    "    'max_value': torch.zeros(105942, dtype=torch.float64, device=device),\n",
    "    'min_value': torch.zeros(105942, dtype=torch.float64, device=device),\n",
    "    'sum_values': torch.zeros(105942, dtype=torch.float64, device=device),\n",
    "    'mean_non_zero': torch.zeros(105942, dtype=torch.float64, device=device),\n",
    "    #'std_dev_non_zero': torch.zeros(105942, dtype=torch.float64, device=device),\n",
    "    # number of consecutive non-zero elements / n_tupels\n",
    "    '1_tups': torch.zeros(105942, dtype=torch.int32, device=device),\n",
    "    '2_tups': torch.zeros(105942, dtype=torch.int32, device=device),\n",
    "    '3_tups': torch.zeros(105942, dtype=torch.int32, device=device),\n",
    "    '4_tups': torch.zeros(105942, dtype=torch.int32, device=device),\n",
    "    '5_tups': torch.zeros(105942, dtype=torch.int32, device=device),\n",
    "    '6_tups': torch.zeros(105942, dtype=torch.int32, device=device),\n",
    "    '7_tups': torch.zeros(105942, dtype=torch.int32, device=device),\n",
    "    '8_tups': torch.zeros(105942, dtype=torch.int32, device=device),\n",
    "    '9_tups': torch.zeros(105942, dtype=torch.int32, device=device),\n",
    "    '10_tups': torch.zeros(105942, dtype=torch.int32, device=device),\n",
    "    '11_tups': torch.zeros(105942, dtype=torch.int32, device=device),\n",
    "    '12_tups': torch.zeros(105942, dtype=torch.int32, device=device),\n",
    "    '13_tups': torch.zeros(105942, dtype=torch.int32, device=device),\n",
    "    '14_tups': torch.zeros(105942, dtype=torch.int32, device=device),\n",
    "    '15_tups': torch.zeros(105942, dtype=torch.int32, device=device),\n",
    "    '16_tups': torch.zeros(105942, dtype=torch.int32, device=device),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c43632f1-8c48-4d32-b4eb-c44e4b9cd5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### OPERATING ON: ../input/open-problems-multimodal/test_multi_inputs.h5 ###\n",
      "### OPERATING ON: ../input/open-problems-multimodal/train_cite_targets.h5 ###\n",
      "### OPERATING ON: ../input/open-problems-multimodal/train_multi_inputs.h5 ###\n",
      "### OPERATING ON: ../input/open-problems-multimodal/train_cite_inputs.h5 ###\n",
      "### OPERATING ON: ../input/open-problems-multimodal/train_multi_targets.h5 ###\n",
      "### OPERATING ON: ../input/open-problems-multimodal/test_cite_inputs.h5 ###\n"
     ]
    }
   ],
   "source": [
    "for f_name in f_list:\n",
    "    print(f\"### OPERATING ON: {f_name} ###\")\n",
    "    # Get properties of dataset\n",
    "    with h5py.File(f_name) as f:\n",
    "        cell_names = [a.decode('utf-8') for a in f[f_name.stem + '/axis1']]\n",
    "        NUM_FEATURES = len(f[f_name.stem + '/axis0'])\n",
    "        \n",
    "    NUM_CELLS = len(cell_names)\n",
    "    CHUNK_SIZE = int(200_000_000 / (NUM_FEATURES))\n",
    "\n",
    "    # the features we want to calculate for every cell\n",
    "    target_features = {\n",
    "        'count_non_zero': torch.zeros(NUM_CELLS, dtype=torch.int32, device=device),\n",
    "        'max_value': torch.zeros(NUM_CELLS, dtype=torch.float64, device=device),\n",
    "        'min_value': torch.zeros(NUM_CELLS, dtype=torch.float64, device=device),\n",
    "        'sum_values': torch.zeros(NUM_CELLS, dtype=torch.float64, device=device),\n",
    "        'mean_non_zero': torch.zeros(NUM_CELLS, dtype=torch.float64, device=device),\n",
    "\n",
    "        # We would like to calc std_dev but currently pytorch does not support it\n",
    "        #'std_dev_non_zero': torch.zeros(NUM_CELLS, dtype=torch.float64, device=device),\n",
    "\n",
    "        # number of consecutive non-zero elements / n_tupels\n",
    "        '1_tups': torch.zeros(NUM_CELLS, dtype=torch.int32, device=device),\n",
    "        '2_tups': torch.zeros(NUM_CELLS, dtype=torch.int32, device=device),\n",
    "        '3_tups': torch.zeros(NUM_CELLS, dtype=torch.int32, device=device),\n",
    "        '4_tups': torch.zeros(NUM_CELLS, dtype=torch.int32, device=device),\n",
    "        '5_tups': torch.zeros(NUM_CELLS, dtype=torch.int32, device=device),\n",
    "        '6_tups': torch.zeros(NUM_CELLS, dtype=torch.int32, device=device),\n",
    "        '7_tups': torch.zeros(NUM_CELLS, dtype=torch.int32, device=device),\n",
    "        '8_tups': torch.zeros(NUM_CELLS, dtype=torch.int32, device=device),\n",
    "        '9_tups': torch.zeros(NUM_CELLS, dtype=torch.int32, device=device),\n",
    "        '10_tups': torch.zeros(NUM_CELLS, dtype=torch.int32, device=device),\n",
    "        '11_tups': torch.zeros(NUM_CELLS, dtype=torch.int32, device=device),\n",
    "        '12_tups': torch.zeros(NUM_CELLS, dtype=torch.int32, device=device),\n",
    "        '13_tups': torch.zeros(NUM_CELLS, dtype=torch.int32, device=device),\n",
    "        '14_tups': torch.zeros(NUM_CELLS, dtype=torch.int32, device=device),\n",
    "        '15_tups': torch.zeros(NUM_CELLS, dtype=torch.int32, device=device),\n",
    "        '16_tups': torch.zeros(NUM_CELLS, dtype=torch.int32, device=device),\n",
    "    }\n",
    "    \n",
    "    # iterate over dataset calculating features\n",
    "    for i in range(int(np.ceil(NUM_CELLS/CHUNK_SIZE))):\n",
    "        ###### SPECIFICATION WHAT DATA TO LOAD AND LOADING OF DATA ONTO DEVICE (CPU OR CUDA) #########\n",
    "        S_INDEX = i * CHUNK_SIZE\n",
    "        E_INDEX = (i+1) * CHUNK_SIZE\n",
    "\n",
    "        # load data and send to torch device\n",
    "        with h5py.File(f_name) as f:\n",
    "            data = torch.tensor(f[f_name.stem + '/block0_values'][S_INDEX : E_INDEX], device=device)\n",
    "\n",
    "            \n",
    "        gc.collect()\n",
    "        ##### CALCULATION OF FEATURES #####\n",
    "        target_features['count_non_zero'][S_INDEX:E_INDEX] = data.gt(0).sum(dim=1)\n",
    "        target_features['max_value'][S_INDEX:E_INDEX] = data.max(dim=1)[0]\n",
    "        target_features['min_value'][S_INDEX:E_INDEX] = data.min(dim=1)[0]\n",
    "        target_features['sum_values'][S_INDEX:E_INDEX] = data.sum(dim=1)\n",
    "\n",
    "\n",
    "        # set zero values to nan (this helps in some computations \n",
    "        # e. g. when computation mean of non zero values)\n",
    "        data[torch.eq(data, 0)] = torch.nan\n",
    "\n",
    "        target_features['mean_non_zero'][S_INDEX:E_INDEX] = data.nanmean(dim=1)\n",
    "\n",
    "        # missing implementation in pytorch (is on their todo)\n",
    "        #target_features['std_dev_non_zero'][S_INDEX:E_INDEX] = data.nanstd(dim=1)\n",
    "\n",
    "        naive_n_tuples = get_naive_n_tuples(data.gt(0), 15)\n",
    "        clean_tuples = clean_naive_n_tuples(naive_n_tuples)\n",
    "\n",
    "        target_features['1_tups'][S_INDEX:E_INDEX] = clean_tuples[0]\n",
    "        target_features['2_tups'][S_INDEX:E_INDEX] = clean_tuples[1]\n",
    "        target_features['3_tups'][S_INDEX:E_INDEX] = clean_tuples[2]\n",
    "        target_features['4_tups'][S_INDEX:E_INDEX] = clean_tuples[3]\n",
    "        target_features['5_tups'][S_INDEX:E_INDEX] = clean_tuples[4]\n",
    "        target_features['6_tups'][S_INDEX:E_INDEX] = clean_tuples[5]\n",
    "        target_features['7_tups'][S_INDEX:E_INDEX] = clean_tuples[6]\n",
    "        target_features['8_tups'][S_INDEX:E_INDEX] = clean_tuples[7]\n",
    "        target_features['9_tups'][S_INDEX:E_INDEX] = clean_tuples[8]\n",
    "        target_features['10_tups'][S_INDEX:E_INDEX] = clean_tuples[9]\n",
    "        target_features['11_tups'][S_INDEX:E_INDEX] = clean_tuples[10]\n",
    "        target_features['12_tups'][S_INDEX:E_INDEX] = clean_tuples[11]\n",
    "        target_features['13_tups'][S_INDEX:E_INDEX] = clean_tuples[12]\n",
    "        target_features['14_tups'][S_INDEX:E_INDEX] = clean_tuples[13]\n",
    "        target_features['15_tups'][S_INDEX:E_INDEX] = clean_tuples[14]\n",
    "        target_features['16_tups'][S_INDEX:E_INDEX] = clean_tuples[15]\n",
    "        # target_features['feature'][S_INDEX:E_INDEX] = \n",
    "    \n",
    "    # calculations done, define index, build dataframe and safe as csv\n",
    "    target_features_cpu = {key:value.cpu() for key, value in target_features.items()}\n",
    "    df = pd.DataFrame(data=target_features_cpu, index=cell_names)\n",
    "    df.to_csv(out_dir / (f_name.stem + '_cells_feature.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:msci]",
   "language": "python",
   "name": "conda-env-msci-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
